{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343b91da-1690-4341-8c50-cfd2d9f9eb79",
   "metadata": {},
   "source": [
    "# Une matrice de distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ccecd1-e6ae-4ffc-9067-65799e52ebf2",
   "metadata": {},
   "source": [
    "Le calcul des fréquences statistiques est souvent la première mesure à réaliser sur un corpus. Elle ouvre ensuite la porte à de nombreuses analyses qui peuvent par exemple aboutir à établir un coefficient de similarité entre les textes qui le composent, à les regrouper par des méthodes de partitionnement ou encore à les comparer à des modèles de langage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b9f0d-aeb4-4e81-9bca-9ebebaf587fd",
   "metadata": {},
   "source": [
    "## Calculer la distance entre deux textes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ef392-a4b9-483f-b8dc-6bd2d89e102a",
   "metadata": {},
   "source": [
    "Prenons un corpus constitué de deux textes :\n",
    "\n",
    "> (A) Le petit chat boit du lait. Le lait n’est pas bon pour les chats.  \n",
    "> (B) Les petits chiens boivent de l’eau. L’eau irait aussi aux chats.\n",
    "\n",
    "Comment mesurer la similitude entre les textes (A) et (B) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680adbe1-4d82-49d3-ad01-fb3d7edea686",
   "metadata": {},
   "source": [
    "### Un exemple trivial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde46f0-65ab-4a0e-888e-21bf9e26c8ad",
   "metadata": {},
   "source": [
    "Une solution courante consiste à calculer la distance qui les sépare, et qui dit distance suppose un point de référence. Si, sur un plan quadrillé de Paris, nous positionnons d’une part le Palais Garnier à deux cases vers l’est et deux vers le nord, et, d’autre part les Halles à cinq cases vers l’est et une vers le sud, nous le faisons par rapport à un point de référence aux coordonnées 0,0 sur les deux axes. Dans notre cas, ce serait alors la place de la Concorde.\n",
    "\n",
    "Or, si se diriger vers l’est d’une case consiste à se déplacer d’une unité vers la droite sur l’axe horizontal du plan ; et que d’autant vers le nord correspond à monter d’une unité sur l’axe vertical, nous pouvons modéliser les informations ainsi :\n",
    "\n",
    "$$\n",
    "\\text{Le Palais Garnier} = \\begin{pmatrix}\n",
    "    \\text{axe horizontal : 2} \\\\\n",
    "    \\text{axe vertical : 2}\n",
    "\\end{pmatrix}\n",
    "\\hspace{2em}\n",
    "\\text{Les Halles} = \\begin{pmatrix}\n",
    "    \\text{axe horizontal : 5} \\\\\n",
    "    \\text{axe vertical : -1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Ou, sachant que $x$ représente l’axe des abscisses et $y$ celui des ordonnées :\n",
    "\n",
    "$$\n",
    "\\text{Le Palais Garnier} = \\begin{pmatrix}\n",
    "    \\text{x : 2} \\\\\n",
    "    \\text{y : 2}\n",
    "\\end{pmatrix}\n",
    "\\hspace{2em}\n",
    "\\text{Les Halles} = \\begin{pmatrix}\n",
    "    \\text{x : 5} \\\\\n",
    "    \\text{y : -1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Les coordonnées étant positionnées dans le même ordre, nous avons ici deux vecteurs $\\vec{A}$ et $\\vec{B}$ dotés de deux attributs (ou dimensions) :\n",
    "\n",
    "$$\n",
    "\\vec{A} = \\begin{pmatrix}\n",
    "    2 \\\\\n",
    "    2\n",
    "\\end{pmatrix}\n",
    "\\hspace{2em}\n",
    "\\vec{B} = \\begin{pmatrix}\n",
    "    5 \\\\\n",
    "    -1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Pour connaître la distance qui les sépare, il suffit maintenant de compter le nombre de cases pour aller de l’un à l’autre sur les deux axes. Pour rejoindre les Halles à partir du Palais Garnier, nous devons nous déplacer de trois cases vers l’est et trois vers le sud. Une soustraction suffit :\n",
    "\n",
    "$$\n",
    "\\delta x = 2 - 5 = -3\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta y = 2 - (-1) = 3\n",
    "$$\n",
    "\n",
    "Nous connaissons la quantité de déplacement sur les deux axes, mais comment faire pour connaître la distance totale ? La première intuition serait de les additionner :\n",
    "\n",
    "$$\n",
    "-3 + 3 = 0\n",
    "$$\n",
    "\n",
    "Il n’y aurait donc aucune distance qui sépare les deux monuments ? Comme nous savons que cet énoncé est faux, nous allons plutôt améliorer le calcul en ne considérant que les valeurs absolues :\n",
    "\n",
    "$$\n",
    "\\lvert -3 \\rvert + \\lvert 3 \\rvert = 6\n",
    "$$\n",
    "\n",
    "Nous pouvons maintenant estimer la quantité de déplacement entre les deux monuments à 6. Du moment que nous conservons la même règle de calcul pour tous les points de notre plan quadrillé et que nous ne modifions pas le point de référence, nous aurons la possibilité d’effectuer des comparaisons sur le seul critère de la distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13afb82-95bd-4067-bfbf-fcddd96129bf",
   "metadata": {},
   "source": [
    "### Vectorisation du corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7831d1-449c-4f02-a955-1096ecbf0025",
   "metadata": {},
   "source": [
    "Si nous considérons les textes (A) et (B) comme deux vecteurs, dans quel espace sont-ils situés et comment trouver leurs coordonnées afin de les placer sur les deux axes ?\n",
    "\n",
    "Commençons par constituer un sac de mots à partir de notre corpus :\n",
    "\n",
    "$$\n",
    "\\text{BOW} = \\text{aller}, \\text{aussi}, \\text{boire}, \\text{bon}, \\text{chat}, \\text{chien}, \\text{eau}, \\text{lait}, \\text{petit}\n",
    "$$\n",
    "\n",
    "L’étape suivante est de compter, pour chacun des textes, le nombre d’occurrences des éléments du sac de mots :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\vec{A} = \\begin{pmatrix}\n",
    "    \\text{(aller :) } &0 \\\\\n",
    "    \\text{(aussi :) } &0 \\\\\n",
    "    \\text{(boire :) } &1 \\\\\n",
    "    \\text{(bon :) } &1 \\\\\n",
    "    \\text{(chat :) } &2 \\\\\n",
    "    \\text{(chien :) } &0 \\\\\n",
    "    \\text{(eau :) } &0 \\\\\n",
    "    \\text{(lait :) } &2 \\\\\n",
    "    \\text{(petit :) } &1 \\\\\n",
    "\\end{pmatrix}\n",
    "\\hspace{5em}\n",
    "\\vec{B} = \\begin{pmatrix}\n",
    "    \\text{(aller :) } &1 \\\\\n",
    "    \\text{(aussi :) } &1 \\\\\n",
    "    \\text{(boire :) } &1 \\\\\n",
    "    \\text{(bon :) } &0 \\\\\n",
    "    \\text{(chat :) } &1 \\\\\n",
    "    \\text{(chien :) } &1 \\\\\n",
    "    \\text{(eau :) } &2 \\\\\n",
    "    \\text{(lait :) } &0 \\\\\n",
    "    \\text{(petit :) } &1 \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Nous remarquons que nos textes ont été modélisés sur davantage de dimensions que les monuments du premier exemple. C’est l’inconvénient de travailler avec le langage, il requiert souvent un espace à très haute dimensionnalité. Deux autres remarques, les vecteurs sont de mêmes dimensions et leurs attributs sont positionnés dans le même ordre.\n",
    "\n",
    "Il nous reste à calculer la somme de leurs différences, ce qui revient, en langage mathématique, à définir **la norme du vecteur** $\\vec{AB}$ :\n",
    "\n",
    "$$\n",
    "\\| \\vec{AB} \\| = \\sqrt{(A_1 - B_1)^2 + (A_2 - B_2)^2 \\dots (A_n - B_n)^2}\n",
    "$$\n",
    "\n",
    "En appliquant la formule d’Euclide, nous trouvons une distance entre les deux vecteurs avoisinant 3,6056 :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\| \\vec{AB} \\| &= \\sqrt{(0 - 1)^2 + (0 - 1)^2 + (1 - 1)^2 + (1 - 0)^2 + (2 - 1)^2 + (0 - 1)^2 + (0 - 2)^2 + (2 - 0)^2 + (1 - 1)^2} \\\\\n",
    "    &= \\sqrt{1 + 1 + 0 + 1 + 1 + 1 + 4 + 4 + 0} \\\\\n",
    "    &= 3,6056\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Il peut paraître déroutant d’annoncer que la distance entre les deux textes est de 3,6056 sans savoir dans quelle unité on parle, mais nous avons établi un système qui nous permettra de comparer les distances entre tous les textes d’un même corpus sur la seule base du calcul de fréquences de certains tokens. Tout l’art sera de parvenir à dégager des traits linguistiques dont il sera intéressant de compter les occurrences.\n",
    "\n",
    "Dernière remarque à ne pas sous-estimer, les calculs effectués ne valent que dans l’espace vectoriel de notre corpus et pour les traits retenus. Si ces paramètres venaient à changer, les mesures ne seraient sans doute pas les mêmes. On peut trouver une forte distance entre deux textes en regard des mots-formes qu’ils emploient, mais une très forte similitude dans l’utilisation des adjectifs en position postnominale par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259fd84-6367-4c82-aaa3-a6c14e3b6cd0",
   "metadata": {},
   "source": [
    "## Étude d’un cas fictif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb229d-0cca-4591-a19d-738423ea8f0d",
   "metadata": {},
   "source": [
    "Considérons un corpus d’une cinquantaine de textes pour lesquels nous avons calculé un score dans cinq catégories à des fins de classification : *Sciences*, *Politique*, *Littérature*, *Journalisme*, *Philosophie*. Ces catégories peuvent être comprises comme les cinq dimensions qui constituent les attributs des vecteurs textes.\n",
    "\n",
    "Pour réaliser notre analyse, nous nous appuierons sur les bibliothèques logicielles *Numpy* pour certains calculs et *Pandas* pour l’affichage des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7f17d-209a-42c4-9497-e9b47cb60dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b620b21-861a-43f1-9853-e1ad2e602b85",
   "metadata": {},
   "source": [
    "Grâce à la méthode `.randint()` du package `.random` de *Numpy*, générons une cinquantaine de scores aléatoires entre 0 et 20 dans cinq catégories :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea65985-fd94-4609-a16b-8e88584e5b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.random.randint(0, 21, size=(50, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528212c3-3602-41ed-a4b2-7d950be581b2",
   "metadata": {},
   "source": [
    "Intégrons à présent les données dans un *data frame* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0325cbe-4dc1-4c93-89ed-632c9a053e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 texts with a score on 5 categories\n",
    "df = pd.DataFrame(\n",
    "    data=scores,\n",
    "    columns=[\"Sciences\", \"Politique\", \"Littérature\", \"Journalisme\", \"Philosophie\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19242ece-fc2c-41f6-9ecc-a98dffa71e10",
   "metadata": {},
   "source": [
    "Consultons les premières lignes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f27c46-3172-4049-b3d6-9159e861c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e826f02-dafb-4f6d-b2f2-fa1ce2dab298",
   "metadata": {},
   "source": [
    "Calculons à présent les normes de tous les vecteurs 2 à 2, ce qui représente un total de $50^2$ combinaisons possibles, avec la méthode `.norm()` du package `.linalg` de *Numpy* qui gère les opérations relatives à l’algèbre linéaire. À noter que pourrions faire l’impasse de calculer la distance d’un vecteur avec lui-même – le résultat attendu étant 0, mais il est plus simple de réaliser la totalité des opérations afin de disposer d’une matrice carrée sans donnée manquante.\n",
    "\n",
    "Première étape, créer une matrice de taille $50 \\times 50$ remplie de 0 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc1227-8295-4630-9a8e-e27ce928b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_distances = np.zeros((len(df), len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cfd2b5-b21d-474d-b968-896947bbbb8f",
   "metadata": {},
   "source": [
    "Nous parcourons ensuite deux fois la liste afin d’assurer la combinatoire et rangeons le résultat du calcul de chaque distance aux indices appropriés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c06efc-a397-4f17-a268-8eac211239df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row_i in enumerate(df.values):\n",
    "    for j, row_j in enumerate(df.values):\n",
    "        pairwise_distances[i, j] = np.linalg.norm(row_i - row_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b7e7c5-b3e5-4eb2-89cf-335541345103",
   "metadata": {},
   "source": [
    "Il ne reste plus qu’à installer ces données dans un nouveau *data frame* afin de les visualiser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32b876-fa07-4421-b65a-20cd3cee2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_df = pd.DataFrame(pairwise_distances, index=df.index, columns=df.index)\n",
    "\n",
    "# print the five first rows and columns\n",
    "distances_df.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c83c4f2-f9e1-45cb-a5c8-7f99fa186e26",
   "metadata": {},
   "source": [
    "Si nous zoomons sur le premier document, lequel parmi les autres lui est le plus proche ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b582d9e-aacf-4508-acad-7c98c2daa50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first document\n",
    "first_doc = distances_df[0]\n",
    "\n",
    "# the lowest non-zero distance\n",
    "mask = first_doc != 0\n",
    "\n",
    "print(f\"Document {np.argmin(first_doc[mask]) + 1} is the nearest from the first document with a score of {np.min(first_doc[mask]):.4f}\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
