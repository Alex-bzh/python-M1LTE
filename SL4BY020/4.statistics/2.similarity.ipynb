{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183757e8-1e04-42f7-a4eb-3d280029de8b",
   "metadata": {},
   "source": [
    "# Évaluer la similitude entre documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2500e23-6fed-432f-88e5-f73344a84ebf",
   "metadata": {},
   "source": [
    "## La similarité cosinus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a61d47-e5a5-433a-a81f-bd3684fd9891",
   "metadata": {},
   "source": [
    "Lorsque l’on parle de similarité de deux vecteurs en traitement automatique du langage naturel, on désigne la **similarité cosinus**, une mesure par laquelle on détermine le cosinus de leur angle dans un intervalle $[-1 , 1]$, où -1 qualifie deux vecteurs opposés, 0 deux vecteurs indépendants et 1 deux vecteurs colinéaires (il serait possible de tracer une droite pour les relier).\n",
    "\n",
    "La formule pour définir la similarité cosinus vaut :\n",
    "\n",
    "$$\n",
    "\\cos \\theta = \\frac{\\vec{A} \\cdot \\vec{B}}{\\| \\vec{A} \\| \\| \\vec{B} \\|}\n",
    "$$\n",
    "\n",
    "Où $\\| \\vec{A} \\| = \\sqrt{\\vec{A} \\cdot \\vec{A}}$\n",
    "\n",
    "Prenons deux vecteurs de dimension 3 :\n",
    "\n",
    "$$\n",
    "\\vec{A} = \\begin{pmatrix}\n",
    "    7 \\\\\n",
    "    32 \\\\\n",
    "    10\n",
    "\\end{pmatrix}\n",
    "\\hspace{2em}\n",
    "\\vec{B} = \\begin{pmatrix}\n",
    "    11 \\\\\n",
    "    4 \\\\\n",
    "    8\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Calculons leur similarité :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\cos \\theta &= \\frac{ (A_1 \\cdot B_1) + (A_2 \\cdot B_2) + (A_3 \\cdot B_3) }{ (\\sqrt{\\vec{A} \\cdot \\vec{A}}) \\times (\\sqrt{\\vec{B} \\cdot \\vec{B}}) } \\\\\n",
    "    \\cos \\theta &= \\frac{ (7 \\times 11) + (32 \\times 4) + (10 \\times 8) }{ (\\sqrt{7^2 + 32^2 + 10^2}) \\times (\\sqrt{11^2 + 4^2 + 8^2}) } \\\\\n",
    "    \\cos \\theta &= \\frac{77 + 128 + 80}{ 34,2491 \\times 14,1774 } \\\\\n",
    "    \\cos \\theta &= \\frac{285}{ 485,5632 } \\\\\n",
    "    \\cos \\theta &\\approx 0,5869\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Selon la nature de $\\vec{A}$ et $\\vec{B}$, nous pourrions avancer que 0,5869 est la mesure de l’indice de ressemblance entre les mots *A* et *B*, ou entre les documents *A* et *B* etc. Une application pratique serait de résoudre par exemple une tâche de classification en effectuant des regroupements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e491dc-d373-4a5e-a69d-5c66a72c66a6",
   "metadata": {},
   "source": [
    "### Vérification dans le triangle quelconque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de1ecf3-6b1f-4e9a-abc2-30e24133307e",
   "metadata": {},
   "source": [
    "Considérons à présent $\\vec{A}$ et $\\vec{B}$ comme des points dans un espace vectoriel reliés à l’origine tel que :\n",
    "\n",
    "$$\n",
    "\\vec{O} = \\begin{pmatrix}\n",
    "    0 \\\\\n",
    "    0 \\\\\n",
    "    0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Nous pouvons estimer la distance de vecteurs passant par $\\vec{OA}$, $\\vec{OB}$ et $\\vec{AB}$ grâce au théorème de Pythagore :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\vec{OA} &= \\sqrt{(O_1 - A_1)^2 + (O_2 - A_2)^2 + (O_3 - A_3)^2} \\\\\n",
    "    &= \\sqrt{(0 - 7)^2 + (0 - 32)^2 + (0 - 10)^2} \\\\\n",
    "    &= \\sqrt{49 + 1024 + 100} \\\\\n",
    "    &= \\sqrt{1173} \\\\\n",
    "    &\\approx 34,2491 \\\\\n",
    "    \\vec{OB} &=\\sqrt{(0 - 11)^2 + (0 - 4)^2 + (0 - 8)^2} \\\\\n",
    "    &= \\sqrt{121 + 16 + 64} \\\\\n",
    "    &\\approx 14,1774 \\\\\n",
    "    \\vec{AB} &=\\sqrt{(7 - 11)^2 + (32 - 4)^2 + (10 - 8)^2} \\\\\n",
    "    &= \\sqrt{16 + 784 + 4} \\\\\n",
    "    &\\approx 28,3549 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "À partir de là, pour trouver $\\cos(O)$, nous pouvons invoquer la loi des cosinus dans un triangle quelconque, de telle manière que :\n",
    "\n",
    "$$\n",
    "\\cos(c) = \\frac{a^2 + b^2 - c^2}{2ab}\n",
    "$$\n",
    "\n",
    "Appliquée à notre exemple, la formule nous donne :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\cos(O) &= \\frac{\\vec{OA}^2 + \\vec{OB}^2 - \\vec{AB}^2}{2 \\cdot \\vec{OA} \\cdot \\vec{OB}} \\\\\n",
    "    &= \\frac{34,2491^2 + 14,1774^2 - 28,3549^2}{2 \\cdot 34,2491 \\cdot 14,1774} \\\\\n",
    "    &= \\frac{1173 + 201 - 804}{2 \\cdot 485,5631} \\\\\n",
    "    &= \\frac{570}{971,1262} \\\\\n",
    "    &\\approx 0,5869\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69272248-9504-4fa6-8fc6-2e4e1fec0ec7",
   "metadata": {},
   "source": [
    "## Similarité de vecteurs binaires : l’indice de Jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de04817-f548-4742-82e1-0e17d014a2a3",
   "metadata": {},
   "source": [
    "Dans l’exemple précédent, les attributs des vecteurs $\\vec{A}$ et $\\vec{B}$ étaient représentés par des nombres pouvant prendre leur valeur dans l’ensemble $\\mathbb{R}$. Et si les possibilités pour les valeurs se limitaient à *0* et *1*, comme dans le cas d’une épreuve de Bernoulli ? Dans ce cas particulier, la similarité peut se calculer avec l’indice de Jaccard :\n",
    "\n",
    "$$\n",
    "J = \\frac{M_{11}}{M_{01} + M_{10} + M_{11}}\n",
    "$$\n",
    "\n",
    "Ou, sachant que *n* est le nombre d’attributs :\n",
    "\n",
    "$$\n",
    "J = \\frac{M_{11}}{n - M_{00}}\n",
    "$$\n",
    "\n",
    "Dans ces formules, les quantités valent :\n",
    "\n",
    "- $M_{00}$ pour le nombre d’attributs qui valent $0$ dans $\\vec{A}$ et $0$ dans $\\vec{B}$ ;\n",
    "- $M_{01}$ pour le nombre d’attributs qui valent $0$ dans $\\vec{A}$ et $1$ dans $\\vec{B}$ ;\n",
    "- $M_{10}$ pour le nombre d’attributs qui valent $1$ dans $\\vec{A}$ et $0$ dans $\\vec{B}$ ;\n",
    "- $M_{11}$ pour le nombre d’attributs qui valent $1$ dans $\\vec{A}$ et $1$ dans $\\vec{B}$.\n",
    "\n",
    "Prenons les deux vecteurs suivants :\n",
    "\n",
    "$$\n",
    "\\vec{A} = \\begin{pmatrix}\n",
    "    0 \\\\\n",
    "    0 \\\\\n",
    "    1 \\\\\n",
    "    1 \\\\\n",
    "    1\n",
    "\\end{pmatrix}\n",
    "\\hspace{2em}\n",
    "\\vec{B} = \\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    0 \\\\\n",
    "    1 \\\\\n",
    "    0 \\\\\n",
    "    0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Après application de la formule, nous obtenons :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    J &= \\frac{1}{1 + 2 + 1} \\\\\n",
    "    J &= \\frac{1}{4} \\\\\n",
    "    J &= 0,25\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3d62c-166c-4ff7-bd8d-733915185643",
   "metadata": {},
   "source": [
    "## Étude d’un cas fictif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a24999-ec62-4aa8-9dda-bed733925d92",
   "metadata": {},
   "source": [
    "Prenons une vingtaine de documents avec une analyse fréquentielle de la longueur de leurs énoncés : phrases de moins de dix mots, phrases de dix à vingt mots et phrases de vingt-et-un mots et plus.\n",
    "\n",
    "Nous utiliserons à nouveau *Pandas* et *Numpy* pour faciliter l’analyse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3fbdfc-6534-4d0f-b09b-749df4d2f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a9451a-c916-4a1a-8063-ce04b62dc327",
   "metadata": {},
   "source": [
    "Générons des données aléatoires et rangeons-les dans un *data frame* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550fdbde-24a3-40f1-9178-fc7776c5e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.random.randint(10, 150, size=(20, 3))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=scores,\n",
    "    columns=[\"< 10 mots\", \"10 à 20 mots\", \"21 mots et +\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb11a3c-6bad-430d-9199-bd1f7628bbe4",
   "metadata": {},
   "source": [
    "Jetons un œil aux données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d494d7d-d591-4d99-afd7-2f77cbf48d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917de6e0-f45d-401c-bf70-1c1533349ce0",
   "metadata": {},
   "source": [
    "Comme ces documents ne sont pas constitués du même nombre de phrases, nous avons besoin de trouver une manière de ramener les fréquences absolues à une même échelle. Pour cela, nous décidons de calculer les fréquences relatives sur 100 phrases :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fe537-34f4-4d34-9eb8-7eec5e92e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = df.sum(axis=1)\n",
    "\n",
    "# divide each value by its corresponding row sum\n",
    "# then multiply by 100\n",
    "relative_frequencies = df.div(row_sums, axis=0) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6180ca-817a-4dc3-8717-ba6ab88428dc",
   "metadata": {},
   "source": [
    "À présent, les fréquences sont toutes normalisées, comme si les documents avaient tous exactement compté 100 phrases.\n",
    "\n",
    "Pour calculer la similarité cosinus entre tous les vecteurs, nous instancions une matrice vide de taille $20 \\times 20$ et la remplissons avec le résultat de la formule vue plus haut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d41fe-2fb3-4ff8-af99-a4c1ed72eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = np.zeros((len(df), len(df)))\n",
    "\n",
    "for i, row_i in enumerate(df.values):\n",
    "    for j, row_j in enumerate(df.values):\n",
    "        cosine_similarities[i, j] = np.dot(row_i, row_j) / np.dot(np.linalg.norm(row_i), np.linalg.norm(row_j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb49e94-f2ac-4da4-a1a5-9bb73dcf82ad",
   "metadata": {},
   "source": [
    "Reste à créer un *data frame* avec la matrice obtenue :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428f5b2-b330-465b-b5f5-21384b2c47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_df = pd.DataFrame(cosine_similarities, index=df.index, columns=df.index)\n",
    "\n",
    "# print the five first rows and columns\n",
    "similarities_df.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f5892-72ff-41ec-aa51-d375a726b572",
   "metadata": {},
   "source": [
    "Intéressons-nous au premier document. Lequel parmi les autres lui est le plus similaire en termes de distribution des longueurs de phrases ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0bba5-44a6-440d-9cba-00e3128de162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first document\n",
    "first_doc = similarities_df[0]\n",
    "\n",
    "# the greatest non-1 score\n",
    "mask = first_doc < 1\n",
    "\n",
    "# max index\n",
    "index_max = first_doc[mask].idxmax()\n",
    "\n",
    "print(f\"Document {index_max + 1} is the most similar with a score of {first_doc[index_max]:.4f}\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
